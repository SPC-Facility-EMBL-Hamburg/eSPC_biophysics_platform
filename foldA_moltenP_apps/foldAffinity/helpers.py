import json
import numpy  as np
import pandas as pd
import codecs
from openpyxl           import load_workbook
from xlrd               import open_workbook

def get_sheet_names_of_xlsx(filepath):

    """

    Get the sheet names of a xls or xlsx file without loading it. 
    The open_workbook function is used so we can handle the error "openpyxl does not support the old .xls file format" 

    """

    try:

        wb = load_workbook(filepath, read_only=True, keep_links=False)
        sheetnames = wb.sheetnames
        
    except:

        xls = open_workbook(filepath, on_demand=True)
        sheetnames =  xls.sheet_names()
 
    return sheetnames

def isBlank (myString):

    return not (myString and myString.strip()) 

def detect_txt_file_type(file):

    '''

    Decide if the file was generated by an Agilent's MX3005P qPCR instrument or a 
    QuantStudio qPCR instrument

    '''

    with codecs.open(file, 'r', encoding='utf-8',errors='ignore') as rf:
        ls       = rf.read().splitlines()

        for line in ls:
            if line.startswith('Segment') and 'Well' in line:
                return 'MX3005P'

            splittedLine = line.split()
            if 'Well' in splittedLine and 'Target' in splittedLine and 'Reading' in splittedLine:
                return 'QuantStudio'

    return None

def subset_panta_data(data,columns_positions):

    """
    Input: 'data' is a dataframe with two columns (temperature and signal) per capillary per signal.
    
    'columns_positions' are the corresponding indexes of the columns where the desired signal is stored.
    These values change according to the signal (330nm, 350nm, Ratio, Scattering).

    Output:

        n x m matrix 'fluo' where m (columns) is the number of different conditions

        Vector of temperatures 'temp' (length n, same number of rows as 'fluo')

    """

    dfs    = [pd.DataFrame(np.array(data.iloc[:,[pos-1,pos]]),
        columns = ["temperature",'signal'+str(i)]) for i,pos in enumerate(columns_positions)]

    # Combine dataframes so we can obtain a vector of temperatures and a matrix of fluorescence signal
    merged = pd.merge_asof(dfs[0].dropna(),dfs[1].dropna(),on="temperature", direction='nearest',allow_exact_matches=True)

    for df in dfs[2:]:
        
        merged = pd.merge_asof(merged,df.dropna(),on="temperature", direction='nearest',allow_exact_matches=True)       
    
    fluo   = np.array(merged.iloc[:, 1:]).astype('float')
    temp   = np.array(merged.iloc[:, 0]).astype('float') 

    # Reduce data so we can plot and fit the data faster.
    while len(temp) > 700:
        fluo = fluo[::2]
        temp = temp[::2]

    return fluo, temp

def getStartLineQuantStudioFile(file_name):

    """
    Returns the number of the first line not starting with "*" + 1
    """

    with codecs.open(file_name, 'r', encoding='utf-8',errors='ignore') as rf:
        ls       = rf.read().splitlines()
        splitted = [l.split() for l in ls]
        
        for i,s in enumerate(splitted):
            if len(s) > 5 and "*" not in s[0]:
                start_row = i+1
                break

    return(start_row)

def generateQS3DataFrame(df):

    df = pd.DataFrame(np.array(df.iloc[:,[3,4]]),
        columns = ["temperature","signal"])

    # Remove commas and convert tu numeric
    df = df.replace(',','', regex=True)
    df[["temperature", "signal"]] = df[["temperature", "signal"]].apply(pd.to_numeric)

    df.sort_values('temperature',inplace=True)

    return df

def generateMergedQuantStudioDataFrame(data):

    dfs = [generateQS3DataFrame(x) for _, x in data.groupby(1)]

    dfs = [df.rename(columns={"signal": 'signal'+str(i)}) for i,df in enumerate(dfs)]

    # Combine dataframes so we can obtain a vector of temperatures and a matrix of fluorescence signal
    merged = pd.merge_asof(dfs[0].dropna(),dfs[1].dropna(),on="temperature", direction='nearest',allow_exact_matches=True)

    for df in dfs[2:]:
        
        merged = pd.merge_asof(merged,df.dropna(),on="temperature", direction='nearest',allow_exact_matches=True)       

    fluo   = np.array(merged.iloc[:, 1:]).astype('float')
    temp   = np.array(merged.iloc[:, 0]).astype('float') 

    # Reduce data so we can plot and fit the data faster.
    while len(temp) > 700:
        fluo = fluo[::2]
        temp = temp[::2]

    return fluo, temp

def filter_fluo_by_temp(np_fluo,np_temp,min_temp,max_temp):

	"""
	Filter the fluorescence matrix using a temperature range

	Requires: 
		
		1) The fluorescence matrix 'np_fluo' of dimensions
	n*m where n is the number of temperatures at which the fluorescence 
	was measured and m the number of conditions  
		2) The temperature vector 'np_temp' of length n.
		3) The lower bound 'min_temp'
		4) The upper bound 'max_temp'


	Returns the filtered fluorescence matrix 
	"""

	np_tog = np.column_stack((np_fluo, np_temp))
	tot = np_fluo.shape[1]
	np_tog = np_tog[np_tog[:,tot ] >= min_temp]
	np_tog = np_tog[np_tog[:,tot] <= max_temp]
	np_tog = np.delete(np_tog, tot, 1)

	return(np_tog)

def filter_temp_by_temp(np_temp,min_temp,max_temp):

	"""
	Filter the temperature vector using a temperature range

	Requires: 
		
		1) The temperature vector 'np_temp' of length n.
		2) The lower bound 'min_temp'
		3) The upper bound 'max_temp'


	Returns the filtered temperature vector 
	"""

	np_temp_filter = np_temp[np_temp >= min_temp]
	np_temp_filter = np_temp_filter[np_temp_filter <= max_temp]

	return(np_temp_filter)


def median_filter_from_fluo_and_temp_vectors(fluo_vec,temp_vec,rolling_window):

    """

    Compute the median filter of the fluorescence vector using a temperature rolling window

    First, we convert the temperature into an integer vector and then 
        into time variable to take advantage of pandas function 
            rolling().median() 


	Requires: 

		1) The fluorescence 1D vector 'fluo_vec'
		2) The temperature  1D vector 'temp_vec'
		3) The size of the rolling window in celsius 'rolling_window'

	Returns the fluorescence vector passed through the median filter


    """

    scaling_factor = 10000 

    temp_vec     =  np.multiply(temp_vec,scaling_factor).astype(int) 
    series       =  pd.Series(fluo_vec,index=temp_vec,dtype=float)
    series.index =  pd.to_datetime(series.index,unit='s')

    roll_window  = str(int(rolling_window*scaling_factor))+"s"

    fluo_df_median_filt = series.rolling(roll_window).median().to_numpy()

    return fluo_df_median_filt


def get_temp_at_maximum_of_derivative(temps,fluo_derivative):

    tms_derivative = np.take(temps, np.argmax(fluo_derivative,axis=0)) 
    return tms_derivative

def get_temp_at_minimum_of_derivative(temps,fluo_derivative):

    tms_derivative = np.take(temps, np.argmin(fluo_derivative,axis=0)) 
    return tms_derivative

def concatenate_fluorescence(temperatures, fluorescence):
    '''
    Concatenate fluorescence matrix in single column matrix
    for global fit
    '''
    reps = fluorescence.shape[1]
    temps = np.tile(temperatures, reps)
    fluors = np.hstack(fluorescence.T)
    return temps, fluors

def round_to_significant_digits(arr, digits):
    rounded_arr = np.zeros_like(arr)
    for i, value in np.ndenumerate(arr):
        if np.abs(value) < np.finfo(float).eps:
            rounded_arr[i] = value  # Keep small numbers close to zero as is
        else:
            magnitude = np.power(10, digits - np.floor(np.log10(np.abs(value))) - 1)
            rounded_arr[i] = np.around(value * magnitude) / magnitude
    return rounded_arr

class NumpyEncoder(json.JSONEncoder):
    
    """

    Special formating to export numpy arrays in a JSON file

    2D numpy arrays will be first converted to list of lists. Each sublist will then be a string with elements separated by ';'
    1D numpy arrays will be converted to lists

    """

    def default(self, obj):
        if isinstance(obj, np.ndarray):

            if np.issubdtype(obj.dtype, np.floating):
                obj = round_to_significant_digits(obj, 4)

            obj = obj.tolist()

            if isinstance(obj, list) and isinstance(obj[0], list):

                for i in range(len(obj)):

                    obj[i] = ';'.join(str(element) for element in obj[i])

                return obj

            else: 

                return obj

        return super(NumpyEncoder, self).default(obj)