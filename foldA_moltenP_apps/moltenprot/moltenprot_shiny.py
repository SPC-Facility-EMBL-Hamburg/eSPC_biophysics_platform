#!/usr/bin/python3
import json

import pandas as pd
import numpy  as np
import numpy.polynomial.polynomial as poly

from scipy.signal     import savgol_filter
from scipy.optimize   import curve_fit
from scipy.integrate  import solve_ivp
from natsort          import index_natsorted

# Load custom helper functions
from helpers                 import *

### Constants
R_gas_constant = 8.314 # In J / ( Kelvin * mol )
temp_standard = 298.15 # In Kelvins, 25 degree Celsius

class DSF_molten_prot_fit:

    """
    Class for nanoDSF protein stability studies
    This class was written by Osvaldo Burastero and is
    based on the work done by Vadim Kotov et al.

    If you use this script please cite:
    
		Kotov, Vadim, et al. "In‐depth interrogation of protein thermal unfolding data with MoltenProt." 
		Protein Science 30.1 (2021): 201-217.

		Burastero, Osvaldo, et al. "eSPC: an online data-analysis platform for molecular biophysics." 
		Acta Crystallographica Section D: Structural Biology 77.10 (2021).

    No warranty whatsoever
    If you have questions or would like to add new models please contact me:
    	oburastero@gmail.com, oburastero@embl-hamburg.de

    Remember -  All models are wrong but some models are useful
                or in other words, any model is at best a useful fiction!!!!!!

    """

    def __init__(self):

        return None

    def init_dictionary_to_store_fluo_temp_data(self):

        """
        Create 2 dictionaries that will share the same keys, i.e., "350nm", but will have different values

        signal_data_dictionary keys contain the signal data (one for each signal) - a n*m matrix where n is the number of measurements and
                                                                                    m is the number of different samples

        temp_data_dictionary   keys contain the temperature (one for each signal) - a vector of length n (same n as before)

        This function has to be called by all the functions that load the DSF data
        For input file examples check spc.embl-hamburg.de

        """

        self.signal_data_dictionary = {}
        self.temp_data_dictionary   = {}

        return None

    def load_nanoDSF_xlsx(self, processed_dsf_file,sheet_names=["350nm","330nm","Scattering","Ratio"]):

        """
        Load the xlsx file (processed) generated by the Nanotemper Prometheus instrument that has one sheet called 'Overview' with a column called 
        'Sample ID' with the names of the samples, and four sheets called 'Ratio', '330nm', '350nm' and 'Scattering'. 
        The first column of the signal sheet ('Ratio', '330nm', '350nm', 'Scattering') should be called 'Time [s]'. 
        The second column should have the temperature data and all subsequent columns store the fluorescence data. 
        The order of the fluorescence columns should match the order of the 'Sample ID' column in the 'Overview' sheet. 

        Input  - file path of the xlsx file and signal that we want to load (should match the sheet names)

        Result - self.signals has the signals we loaded i.e., ["350nm","330nm","Scattering","Ratio"]
                 self.signal_data_dictionary and self.temp_data_dictionary have the signal and temperature data
                 self.conditions (and self.conditions_original) has the sample names, if present.
        """

        # Load excel file (this needs to be the processed file!)
        xls = pd.ExcelFile(processed_dsf_file)
        
        conditions_df = pd.read_excel(xls, "Overview")

        conditions    = conditions_df[['Sample ID']].values.flatten().astype(str)

        self.conditions_original = conditions
        # Add position index to avoid problems with empty names

        self.conditions = [cond + " P" + str(i+1) if isBlank(cond) else cond for i,cond in enumerate(conditions) ] 

        self.init_dictionary_to_store_fluo_temp_data()

        possible_signals    = ["350nm","330nm","Scattering","Ratio"]

        include             = []

        # Change signal name if unfolding curve is present
        for sn in sheet_names:

            include_value = any([ps in sn and "deriv" not in sn.lower() for ps in possible_signals])

            include.append(include_value)

        sheet_names_to_load = np.array([s for (i, s) in zip(include, sheet_names) if i])

        self.signals        = sheet_names_to_load

        for signal in self.signals:

            dat = pd.read_excel(xls, signal, index_col=None, header=None)

            indices   = np.argwhere(dat.iloc[:, 0].values == 'Time [s]')
            first_row = int(indices[0][0]) + 1

            #first_row = int(np.argwhere(list(dat.iloc[:, 0] == 'Time [s]'))) + 1

            fluo   = np.array(dat.iloc[first_row:, 2:]).astype('float')
            temp   = np.array(dat.iloc[first_row:, 1]).astype('float') + 273.15 # To kelvin 

            # Reduce data so we can plot and fit the data faster.
            while len(temp) > 700:
            	fluo = fluo[::2]
            	temp = temp[::2]

            self.signal_data_dictionary[signal]   = fluo
            self.temp_data_dictionary[signal]     = temp

        return None

    def load_tycho_xlsx(self,file):
        
        """
        Load the xlsx file generated by the Nanotemper Prometheus Tycho instrument. 
        This file has one sheet called ‘Results’ (with 6 columns named '#', 'Capillary label',..., 'Sample Brightness'), 
        and one sheet called 'Profiles_raw' where the fluorescence data is stored.

        The ‘Profiles_raw’ sheet columns should have the following structure:

        One row with information about the recorded signal, e.g., ‘Ratio 350 nm / 330 nm’,  ‘Brightness @ 330 nm’, ‘Brightness @ 350 nm’.
        One row with the capillary numbers.
        One row with the time, temperature and sample names.
        The remaining rows store the temperature and signal data.

        Input  - file path of the xlsx file 

        Result - self.signals has the signals we loaded i.e., ["350nm","330nm","Scattering","Ratio"]
                 self.signal_data_dictionary and self.temp_data_dictionary have the signal and temperature data
                 self.conditions (and self.conditions_original) has the sample names, if present.

        """

        xls = pd.ExcelFile(file)
        
        # Retrieve the conditions names - in sheet "Results"
        df = pd.read_excel(xls, "Results")

        for colIndex, column in enumerate(df):

            columnValues      = df[column]
            has_desired_value = columnValues.isin(["Capillary label"])

            if any(has_desired_value):

                rowIndexBegin   = np.flatnonzero(has_desired_value)[0]+1
                initialRatioCol = df.iloc[rowIndexBegin:,colIndex+4]
                try:
                    rowIndexEnd     = np.flatnonzero(initialRatioCol.isnull())[0] + rowIndexBegin
                except:
                    rowIndexEnd     = rowIndexBegin+6
                break

        conditions         = np.array(df.iloc[rowIndexBegin:rowIndexEnd,colIndex])
        numberOfConditions = len(conditions)

        self.conditions_original = conditions
        # Add position index to avoid problems with empty names
        self.conditions = [cond + " P" + str(i+1) if isBlank(cond) else cond for i,cond in enumerate(conditions) ] 

        self.init_dictionary_to_store_fluo_temp_data()

        # Retrieve the fluorescence signal - in sheet "Profiles_raw"
        df = pd.read_excel(xls, "Profiles_raw")

        for colIndex, column in enumerate(df):

            columnValues      = df[column]
            has_desired_value = columnValues.isin(["Temperature [°C]"])

            if any(has_desired_value):

                rowIndexBegin   = np.flatnonzero(has_desired_value)[0]+1
                rowIndexEnd     = np.flatnonzero(columnValues[(rowIndexBegin):].isnull())[0]+rowIndexBegin

                temperature     = np.array(df.iloc[rowIndexBegin:rowIndexEnd,colIndex]).astype('float') + 273.15 # To kelvin 

                break

        columnNames  = df.iloc[rowIndexBegin-1,:]

        startIndexes = [i for i, j in enumerate(columnNames) if j == conditions[0]]

        signals      = np.array(df.iloc[rowIndexBegin-3,startIndexes])
        signalsClean = []
        
        for s in signals:
            if "ratio" in s.lower():
                signalsClean.append("Ratio")
            else:  
                if "330" in s.lower() :
                    signalsClean.append("330nm")
                if "350" in s.lower():
                    signalsClean.append("350nm")

        for i, signal in enumerate(signalsClean):

            colStartIndex   = startIndexes[i]
            colEndIndex     = colStartIndex + numberOfConditions

            fluo            = np.array(df.iloc[rowIndexBegin:rowIndexEnd,colStartIndex:colEndIndex]).astype('float') 
            temp            = temperature

            while (len(temp)) > 600:

                fluo = fluo[::2]
                temp = temp[::2]

            self.signal_data_dictionary[signal]   = fluo
            self.temp_data_dictionary[signal]     = temp

        self.signals        = np.array(signalsClean)

        return None

    def load_Thermofluor_xlsx(self,thermofluor_file):

        """
        Load DSF Thermofluor xls file and extract data
        The xls file generated by the ThermoFluor assay in a qPCR instrument. 
        This file has one sheet called 'RFU' where the first row has the sample positions (header), the first column has the temperature data,
        and all subsequent columns store the fluorescence data. 

        Input  - file path of the xls file and signal that we want to load

        Result - 
                 self.signal_data_dictionary and self.temp_data_dictionary have the signal and temperature data
                 self.conditions (and self.conditions_original) has the sample names.

        """

        xls  = pd.ExcelFile(thermofluor_file)
        dat = pd.read_excel(xls, "RFU",header=None)
        conditions = np.array(dat.iloc[0, 1:])

        self.conditions_original = conditions
        self.conditions = conditions

        self.init_dictionary_to_store_fluo_temp_data()

        signal = "DSF_RFU"
        self.signal_data_dictionary[signal]   = np.array(dat.iloc[1:,1:]).astype('float')
        self.temp_data_dictionary[signal]     = np.array(dat.iloc[1:, 0]).astype('float') + 273.15 # To kelvin

        self.signals = np.array([signal])

        return None

    def load_panta_xlsx(self,pantaFile):

        """
        Load the xlsx file generated by a Prometheus Panta instrument. 
        This file has one sheet called ‘Overview’ with a column called 'Sample ID' with the names of the samples, 
        and one sheet called ‘Data Export’ where all the data is stored. The ‘Data Export’ sheet columns should have the following order:

        Temperature capillary 1 ; Ratio capillary 1 ; … ; Temperature capillary 1 ; 350 nm capillary 1 ; … ; 
        Temperature capillary 1 ; 330 nm capillary 1 ; … ; Temperature capillary 1 ; scattering capillary 1 ; … ; 
        Temperature capillary 2 ; Ratio capillary 2; … ;  Temperature capillary n ; Ratio capillary n.

        Columns whose names include "Derivative" ​​are not read.

        Input  - file path of the xlsx file and signal that we want to load (should match the sheet names)

        Result - self.signals has the signals we loaded i.e., ["350nm","330nm","Scattering","Ratio"]
                 self.signal_data_dictionary and self.temp_data_dictionary have the signal and temperature data
                 self.conditions (and self.conditions_original) has the sample names, if present.

        """

        try:

            data          = pd.read_excel(pantaFile, "Data Export")

        except:

            data          = pd.read_excel(pantaFile, "melting-scan") # Alternative format of PANTA


        column_names  = [str.lower(c) for c in data.columns]

        pos_350       = [i for i,x in enumerate(column_names) if "350"   in x and "deriv" not in x and "330" not in x]
        pos_330       = [i for i,x in enumerate(column_names) if "330"   in x and "deriv" not in x and "350" not in x]
        scattering    = [i for i,x in enumerate(column_names) if "scattering"   in x and "deriv" not in x]
        pos_ratio     = [i for i,x in enumerate(column_names) if "ratio" in x and "deriv" not in x]

        possible_signals    = ["350nm","330nm","Scattering","Ratio"]
        signals             = []
        self.init_dictionary_to_store_fluo_temp_data()

        all_positions = [pos_350,pos_330,scattering,pos_ratio]

        for positions,signal in zip(all_positions,possible_signals):

            if len(positions) > 0:

                fluo, temp = subset_panta_data(data,positions)

                self.signal_data_dictionary[signal]   = fluo
                self.temp_data_dictionary[signal]     = temp 

                signals.append(signal)

        self.signals        = np.array(signals)

        try:

            conditions_df = pd.read_excel(pantaFile, "Overview")
            conditions    = conditions_df[['Sample ID']].values.flatten().astype(str)

        except:

            conditions = np.repeat('',fluo.shape[1])


        self.conditions_original = conditions
        # Add position index to avoid problems with empty names
        self.conditions = [cond + " P" + str(i+1) if isBlank(cond) else cond for i,cond in enumerate(conditions) ] 

        return None

    def load_QuantStudio_txt(self,QSfile):

        """

        Input: A txt file ('QSfile') where column 2 has the well position, 
        column 3 the temperature and column 4 the fluorescence signal. Index starts at 1!!!

        --- Caution ---
        The first rows of the file are comments that start with '*' and are not readed
        The temperature and signal column have commas that need to be deleted

        Columns are separated by spaces

        Input  - file path of the txt file 

        Result - 
                 self.signal_data_dictionary and self.temp_data_dictionary have the signal and temperature data
                 self.conditions (and self.conditions_original) has the sample names, if present.

        """

        start_row = getStartLineQuantStudioFile(QSfile)
        data      = pd.read_csv(QSfile,skiprows=start_row,sep=r"\s+",header=None)

        u, ind     = np.unique(data.iloc[:,1], return_index=True)
        conditions = u[np.argsort(ind)]

        self.conditions_original = conditions
        self.conditions = conditions

        fluo , temp = generateMergedQuantStudioDataFrame(data)

        self.init_dictionary_to_store_fluo_temp_data()
        signal = "Fluorescence"

        self.signal_data_dictionary[signal]   = fluo
        self.temp_data_dictionary[signal]     = temp
        self.signals = np.array([signal])

        return None

    def load_Agilents_MX3005P_qPCR_txt(self,filename):

        """
        Input: A txt file where the 2nd column has the fluorescence data, and 
        the 3rd column the temperature. 
        Wells are separated by rows containing a sentence like this one: 'Segment  2 Plateau  1 Well  1' 
        """

        dfs      = []
        well_num = []

        with open(filename, 'r') as f:

            ls  = f.read().splitlines()

            for i,line in enumerate(ls):
                if line.startswith('Segment') and 'Well' in line:
                    # Get the well number
                    well_num .append(line.split()[-1])

                    fluorescence = []
                    temperature  = []

                    for line2 in ls[i+2:]:
                        if line2.startswith('Segment'):
                            break
                        else:
                            data = line2.split()
                            fluorescence.append(float(data[1]))
                            temperature.append(float(data[2]))

                    df = pd.DataFrame({'temperature':temperature,'signal'+str(well_num):fluorescence})
                    df.sort_values('temperature',inplace=True)
                    dfs.append(df)

        # Combine dataframes so we can obtain a vector of temperatures and a matrix of fluorescence signal
        merged = pd.merge_asof(dfs[0].dropna(),dfs[1].dropna(),on="temperature", direction='nearest',allow_exact_matches=True)

        for df in dfs[2:]:
            
            merged = pd.merge_asof(merged,df.dropna(),on="temperature", direction='nearest')       

        fluo   = np.array(merged.iloc[:, 1:]).astype('float')
        temp   = np.array(merged.iloc[:, 0]).astype('float')  

        # Reduce data so we can plot and fit the data faster.
        while len(temp) > 700:
            fluo = fluo[::2]
            temp = temp[::2]

        self.init_dictionary_to_store_fluo_temp_data()
        signal = "Fluorescence"

        self.conditions_original            = well_num
        self.conditions                     = well_num
        self.signal_data_dictionary[signal] = fluo
        self.temp_data_dictionary[signal]   = temp + 273.15 # To kelvin

        self.signals = np.array([signal])

        return None

    def load_csv_file(self,file):

        """

        Input: A csv file where the first column has the temperature and all the next columns the 
        fluorescence data, header is required

        """

        dat            = pd.read_csv(file)

        conditions  = [str(c) for c in dat.columns[1:]]
        
        self.conditions            = conditions
        self.conditions_original   = conditions

        self.init_dictionary_to_store_fluo_temp_data()

        signal = "Fluorescence"

        self.signal_data_dictionary[signal]   = np.array(dat.iloc[:,1:]).astype('float')
        self.temp_data_dictionary[signal]     = np.array(dat.iloc[:, 0]).astype('float')  + 273.15 # To kelvin
        self.signals = np.array([signal])

        return None

    def load_supr_dsf(self,JSON_file):

        self.init_dictionary_to_store_fluo_temp_data()

        # Read JSON data from a file
        with open(JSON_file, "r") as file:
            json_data = file.read()

        # Parse JSON data into a dictionary
        data_dict     = json.loads(json_data)
        data_dict_new = {}

        samples   = data_dict['Samples']
        
        samples_name = [item["SampleName"] for item in data_dict['Samples']]
        samples_well = [item["WellLocations"] for item in data_dict['Samples']]

        samples_name_simple = []
        samples_well_simple = []

        for sn,sw in zip(samples_name,samples_well):

            if ',' in sw:

                sw = sw.split(',')
                sn = [sn for _ in sw]

            else:

                sw = [sw]
                sn = [sn]

            samples_name_simple += sn
            samples_well_simple += sw

        name_df = pd.DataFrame({
            'well': samples_well_simple,
            'name': samples_name_simple})

        scans   = [item["_scans"] for item in data_dict['Wells']]
        n_scans = len(scans)

        wavelengths   = data_dict['Wavelengths']
        wavelengths   = np.round(wavelengths, decimals=1)
        n_wavelengths = len(wavelengths)

        temperatures = []
        signals      = []

        temperature_fixed = np.arange(5,110,0.5)

        well = [item["PhysicalLocation"] for item in data_dict['Wells']]

        # Create a categorical data type with the custom order
        cat_type = pd.CategoricalDtype(categories=well, ordered=True)

        # Convert the column to the categorical data type
        name_df['well'] = name_df['well'].astype(cat_type)

        # Sort the DataFrame based on the custom order
        name_df = name_df.sort_values(by='well')

        conditions = name_df['name'].values.astype(str)

        self.conditions_original =  conditions
        self.conditions          =  conditions

        for i in range(n_scans):

            temperatures.append([item['Temperature'] for item in scans[i]])
            signals.append([item['Signal']           for item in scans[i]])

        temperatures = np.array(temperatures).T
        temperatures = np.round(temperatures, decimals=1)

        signals = np.array(signals)

        # Iterate over the wavelengths
        
        named_wls = [str(wl) + 'nm' for wl in wavelengths]

        for i in range(n_wavelengths):

            signals_temp  = signals[:,:,i].T
            signal_interp = []

            # Iterate over the columns of the arrays
            for ii in range(n_scans):

                x = temperatures[:, ii]
                y = signals_temp[:, ii]

                sorted_indices = np.argsort(x)
                x = x[sorted_indices]
                y = y[sorted_indices]

                y_interpolated = np.interp(temperature_fixed, x, y,left=np.nan,right=np.nan)

                # Linear interpolation every 0.5 degrees
                signal_interp.append(y_interpolated)

            fluo = np.array(signal_interp).T
            
            non_nas  = np.logical_not(np.isnan(fluo).any(axis=1))

            wl = named_wls[i]
            self.signal_data_dictionary[wl]   = fluo[non_nas,:]
            self.temp_data_dictionary[wl]     = temperature_fixed[non_nas] + 273.15 # To kelvin 

        # Add the ratio signal
        try:
            
            signal_name = 'Ratio 350nm/330nm'

            diff_350 = np.abs(wavelengths - 350)
            diff_330 = np.abs(wavelengths - 330)

            # Check if we have wavelengthd data between 349 - 351 nm and between 329 - 331 nm.
            if np.min(diff_350) < 1 and np.min(diff_330) < 1:

                idx350 = np.argmin(diff_350)
                idx330 = np.argmin(diff_330)


                f350   =  self.signal_data_dictionary[named_wls[idx350]]
                f330   =  self.signal_data_dictionary[named_wls[idx330]]

                fRatio = f350 / f330

                self.signal_data_dictionary[signal_name] = fRatio
                self.temp_data_dictionary[signal_name]   = self.temp_data_dictionary[named_wls[idx350]]

                named_wls = [signal_name] + named_wls

        except:

            pass

        self.signals = np.array([named_wls])

        return None

    def set_signal(self,which):

        """
        Assign self.fluo and self.temps according to the desired signal

        self.fluo is a n*m matrix where n is the number of measurements and m is the number of different samples
        self.temps is a vector of length n (same n as before)

        Assign self.dt (averague value of the temperature step in self.temps), 
        and set the signal we are analyzing, i.e., "350nm"

        """

        self.fluo   = self.signal_data_dictionary[which]
        self.temps  = self.temp_data_dictionary[which]

        self.set_dt()
        self.set_signal_type(which)

    def set_dt(self):

        """
        Get averague value of the temperature step in self.temps
        """

        self.dt         = ( max(self.temps) - min(self.temps) ) / (len(self.temps) - 1)

        return None

    def set_signal_type(self,which):
        
        """
        Set the signal we want to analyze, i.e., "DSF_RFU", "350nm", ...
        """

        self.signal_type = which

        return None

    def sort_by_conditions_name(self,sort=False):

        """
        Re order the samples according to the sample names - check index_natsorted function from the natsort package
        """

        self.conditions_original = np.array(self.conditions_original)

        if sort:

            ind                      = index_natsorted(self.conditions_original)
            self.conditions_original = self.conditions_original[ind]
            self.conditions          = self.conditions_original
            self.signal_data_dictionary = {k: v[:,ind] for k, v in self.signal_data_dictionary.items()}

            # Get idx so we can reverse the sorting.
            self.idx_no_sorted   = [ind.index(i) for i in range(len(ind))]

        else:

            ind                      = self.idx_no_sorted
            self.conditions_original = self.conditions_original[ind]
            self.conditions          = self.conditions_original
            self.signal_data_dictionary = {k: v[:,ind] for k, v in self.signal_data_dictionary.items()}

        return None

    def select_signal_columns(self,columns_to_include):

        """
        Select a subset of samples that we want to analyze    
    
        Input  - a 1D boolean array 'columns_to_include'
        Result - self.fluo with a subset of samples
        """

        if isinstance(columns_to_include, bool):

            columns_to_include = np.array([columns_to_include]) 

        self.fluo = self.fluo[:,columns_to_include]

        return None

    def median_filter(self,n_degree_window):

        """

        Use this function if the fluorescence curves present spikes. It applies a
        rolling median window filter 

        Input - an integer 'n_degree_window'

        Result - smoothed self.fluo 

        """

        self.fluo = np.apply_along_axis(median_filter_from_fluo_and_temp_vectors,0,
            self.fluo,self.temps,n_degree_window)

        return None

    def estimate_fluo_derivates(self,temp_window_length=8):

        """
        Compute the 1st and 2nd derivative of self.fluo using the Savitzky-Golay-Filter
        Estimate the melting temperature based on the derivative peaks (maximums or minimums)

        Input - an integer 'temp_window_length' that is the window_length for the Savitzky-Golay-Filter

        Result - we assign self.derivative, self.derivative2 and self.tms_from_deriv

        """

        # No derivative if we don't have enough temperature data
        if ( (np.max(self.temps) - np.min(self.temps)) < 16):  

            self.tms_from_deriv = None
            self.derivative     = None
            self.derivative2    = None

            return None

        odd_n_data_points_window_len         = np.ceil(temp_window_length / self.dt) // 2 * 2 + 1
        odd_n_data_points_window_len_2nd_der = np.ceil((temp_window_length+5) / self.dt) // 2 * 2 + 1

        self.derivative = savgol_filter(self.fluo,axis=0,
            window_length=odd_n_data_points_window_len,polyorder=4,
            deriv=1,mode="nearest")

        self.derivative2 = savgol_filter(self.fluo,axis=0,
            window_length=odd_n_data_points_window_len_2nd_der,polyorder=4,
            deriv=2,mode="nearest")

        """
        
        Estimate Tm from the derivative curve
        To do this, we first shift the first derivative by using the mean of the 
            median of the first and last 5 degrees of each melting curve.

        """

        der_temp_init = filter_fluo_by_temp(self.derivative,
            self.temps,min(self.temps)+6,min(self.temps)+11)

        der_temp_end  = filter_fluo_by_temp(self.derivative,
            self.temps,max(self.temps)-11,max(self.temps)-6)

        med_init  = np.median(der_temp_init,axis=0)
        med_end   = np.median(der_temp_end ,axis=0)   
        mid_value = np.array([(x+y)/2 for x,y in zip(med_init,med_end)])

        der_temp = filter_fluo_by_temp(self.derivative,
            self.temps,min(self.temps)+6,max(self.temps)-6)

        mid_value = mid_value * np.where(mid_value>0,1,-1)

        der_temp = np.add(der_temp,mid_value) 

        temp_temp = filter_temp_by_temp(self.temps,min(self.temps)+6,max(self.temps)-6)

        max_der = np.amax(der_temp,axis=0)
        min_der = np.amin(der_temp,axis=0)

        der_direction_temp = [abs(maxd) > abs(mind) for maxd,mind in zip(max_der,min_der)]

        if  sum(der_direction_temp) > (len(der_direction_temp) / 2):

            self.tms_from_deriv = get_temp_at_maximum_of_derivative(temp_temp,der_temp)

        else:

            self.tms_from_deriv = get_temp_at_minimum_of_derivative(temp_temp,der_temp)


        return None

    def estimate_baselines_parameters(self,baseline_degree_window):

        """

        Estimate the temperature dependence of the native/unfolded state fluorescence.

        Input - an integer 'baseline_degree_window' that is the temperature window to fit the equation of a line

        Result - we assign self.bNs, self.bUs, self.kNs, self.kUs
    
        kN, bN: slope and intercept of the pre-transition baseline Native State 
        kU, bU: slope and intercept of the post-transition baseline, Unfolded State 

        """

        max_native_temp   = min(self.temps) + baseline_degree_window
        min_unfolded_temp = max(self.temps) - baseline_degree_window

        native_fluo       = filter_fluo_by_temp(self.fluo,self.temps,
            min(self.temps),max_native_temp)

        native_temps      = filter_temp_by_temp(self.temps,min(self.temps),max_native_temp)

        unfolded_fluo     = filter_fluo_by_temp(self.fluo,self.temps,
            min_unfolded_temp,max(self.temps))

        unfolded_temps    = filter_temp_by_temp(self.temps,min_unfolded_temp,max(self.temps))

        coef_Native, stats_Native     = poly.polyfit(native_temps,    native_fluo,1,full=True)
        coef_Unfolded, stats_Unfolded = poly.polyfit(unfolded_temps, unfolded_fluo,1,full=True)

        self.bNs, self.kNs  = coef_Native[0],   coef_Native[1]
        self.bUs, self.kUs  = coef_Unfolded[0], coef_Unfolded[1]

        self.tms_initial = estimate_initial_tm_from_baseline_fitting(self.bUs,self.bNs,
            self.kNs,self.kUs,self.temps,baseline_degree_window,self.derivative)

        return None

    def initialize_model(self,model_name,params_name):

        """

        Initialize attributes, this function should be called internally  
        before fitting the fluorescence data to a model

        The idea is then to generate a model function that can be optimized using scipy_fit routine

            Scipy_fit optimizes ydata = f(xdata, *params) 

            In our case, 'T' is the temperature vector (xdata) and 
            kN, bN, kU, bU, dHm, Tm are for example in self.EquilibriumTwoState the parameters to fit.
            The fluorescence values represent the ydata

        """

        self.model_name  = model_name   # EquilibriumTwoState, EmpiricalTwoState, ...
        self.params_name = params_name  # i.e. ['kN', 'bN', 'kU', 'bU', 'dHm', 'Tm']

        #  fitted_conditions_indexes is a list of integers: indexes of the conditions that could be 'succesfully' fitted
        self.fitted_conditions_indexes  = []
        
        self.params_all                 = [] # values of the fitted parameters
        self.errors_abs_all             = [] # std error of the fitted parameters
        self.errors_percentage_all      = [] # relative error of the fitted parameters
        self.fluo_predictions_all       = [] # Predicted signal
        self.std_error_estimate_all     = [] # std error of the fitting
        self.parameters_far_from_bounds = [] # Boolean, check that the parameters are far from the fitting bounds

        return None

    def fit_model_and_fill_params_and_errors(self,model_function,initial_estimates,
        low_bounds,high_bounds,fit_algorithm="trf"):

        """

        Perform the fitting according to the model function and boundaries
        Fill the attributes initialized when calling self.initialize_model()

        """

        for index in range(self.fluo.shape[1]):

            low_bound     =  low_bounds[index]
            high_bound    =  high_bounds[index]
            p0            =  initial_estimates[index]

            fluo_vec      =  self.fluo[:,index].flatten()

            try: 

                params, cov = curve_fit(model_function, self.temps,fluo_vec, 
                    p0=p0, bounds=(tuple(low_bound), tuple(high_bound)),
                    max_nfev=5E4, method=fit_algorithm)

                # Check if we are close to the fitting boundaries
                estimation_quality = check_good_parameters_estimation(params,low_bound,high_bound,self.params_name)
                self.parameters_far_from_bounds.append(estimation_quality)

                errors = np.sqrt(np.diag(cov))

                self.params_all.append(params)
                self.errors_abs_all.append(errors)
                self.errors_percentage_all.append(abs(errors / params) * 100)

                fluo_predictions      = model_function(self.temps,*params)

                sum_square_residuals = np.sum( ( fluo_predictions - fluo_vec ) ** 2)
                std_error_estimate   = np.sqrt( sum_square_residuals / len(fluo_vec))

                self.fluo_predictions_all.append(fluo_predictions)
                self.std_error_estimate_all.append(std_error_estimate)
                self.fitted_conditions_indexes.append(index)

            except:
                pass

        if self.fitted_conditions_indexes:

            self.fitted_conditions     = [self.conditions[index] for index in self.fitted_conditions_indexes]
            self.fitted_fluo           =  self.fluo[:,np.array(self.fitted_conditions_indexes)]
            self.get_baseline_separation_factor()

        return None

    def get_baseline_separation_factor(self):

        """

        Get the baseline_separation_factor 
        To use this method, run first at least one fitting model with the 5 parameters
        'kN, 'bN', 'kU', 'bU' and 'Tm' 

        If they are not present in the model parameters, 
            the baseline factor will be set to 1 to all fitted conditions

        """

        required_parameters = ['kN', 'bN', 'kU', 'bU', 'Tm'] 

        params_present =  all(req_param in self.params_name  for req_param in required_parameters)

        if not params_present:

            self.baseline_factor_all = [1 for _ in range(len(self.fitted_conditions))]

            return None

        self.baseline_factor_all        = []
        position_of_required_parameters = [self.params_name.index(param) for param in required_parameters]
    
        for index in range(len(self.fitted_conditions)):

            params_of_condition_index  = np.array(self.params_all[index])
            kN, bN, kU, bU, Tm    = params_of_condition_index.take(position_of_required_parameters, 0)

            std_error_estimate      = self.std_error_estimate_all[index]
            baseline_factor = estimate_baseline_factor(kN, bN, kU, bU, Tm, std_error_estimate)

            self.baseline_factor_all.append(baseline_factor)

        return None

    def EquilibriumTwoState(self,fit_algorithm="trf"):

        """
        This thermodynamic-based model presupposes that the protein only exists in the native (folded) or unfolded state and that there 
        is an equilibrium between these two states given by the unfolding reaction N ⇆ U.

        Result - we perform the fitting and assign the values to 

        self.model_name,            self.params_name,               self.fitted_conditions_indexes  
        self.params_all,            self.errors_abs_all,            self.errors_percentage_all      
        self.fluo_predictions_all,  self.std_error_estimate_all,    self.parameters_far_from_bounds 

        """

        params_name = ['kN', 'bN', 'kU', 'bU', 'dHm', 'Tm']

        self.initialize_model("EquilibriumTwoState",params_name)

        def model(T, kN, bN, kU, bU, dHm, Tm):

            return ((kN * T + bN + (kU * T + bU) * np.exp(dHm / R_gas_constant * 
                (1 / Tm - 1 / T)))) / (1 + np.exp(dHm / R_gas_constant * (1 / Tm - 1 / T)))

        init_dH = 60000
        
        low_bounds        = []
        high_bounds       = []
        initial_estimates = []

        for index in range(self.fluo.shape[1]):

            tm_init = self.tms_initial[index]

            p0 = (self.kNs[index], self.bNs[index], self.kUs[index], self.bUs[index], init_dH, tm_init)

            low_bound    =  [0.3*x if x>0 else 1.7*x for x in p0[:-2]] + [0,min(self.temps)+5]
            high_bound    = [1.7*x if x>0 else 0.3*x for x in p0[:-2]] + [3140098,max(self.temps)-5] 

            initial_estimates.append(p0)
            low_bounds.append(low_bound)
            high_bounds.append(high_bound)

        self.fit_model_and_fill_params_and_errors(model,initial_estimates,low_bounds,
            high_bounds,fit_algorithm)

        dHm_all,      Tm_all     = [p[4] for p in self.params_all],     [p[5] for p in self.params_all]
        dHms_sd_all,  Tm_sd_all  = [p[4] for p in self.errors_abs_all], [p[5] for p in self.errors_abs_all]

        self.dG_std , self.dCp_component = get_EquilibriumTwoState_model_dGstd(dHm_all,Tm_all,self.cp)
        self.T_onset = get_EquilibriumTwoState_model_Tons(dHm_all,Tm_all,dHms_sd_all,Tm_sd_all)

        return None

    def EquilibriumThreeState(self,t1min,t1max,t2min,t2max,fit_algorithm="trf"):

        """

        This model adds the presence of one short-lived protein state: native (N), intermediate (I) and unfolded (U). 

        Input

        t1min and t1max are the max and min accepted values for the parameter T1. (N ⇆ I)
        t2min and t2max are the max and min accepted values for the parameter T2. (I ⇆ U)

        Result - we perform the fitting and assign the values to 

        self.model_name,            self.params_name,               self.fitted_conditions_indexes  
        self.params_all,            self.errors_abs_all,            self.errors_percentage_all      
        self.fluo_predictions_all,  self.std_error_estimate_all,    self.parameters_far_from_bounds 

        """

        params_name = ['kN', 'bN', 'kU', 'bU', 'kI', 'dHm1', 'T1', 'dHm2', 'T2']

        self.initialize_model("EquilibriumThreeState",params_name)

        def model(T, kN, bN, kU, bU, kI, dHm1, T1, dHm2, T2):

            return (kN * T + bN + kI * np.exp(dHm1 / R_gas_constant * (1 / T1 - 1 / T)) + (kU * T + bU)*
                np.exp(dHm1 / R_gas_constant * (1 / T1 - 1 / T)) * np.exp(dHm2 / R_gas_constant * (1 / T2 - 1 / T))) / (1 + 
                np.exp(dHm1 / R_gas_constant * (1 / T1 - 1 / T)) + np.exp(dHm1 / R_gas_constant * (1 / T1 - 1 / T)) *  
                np.exp(dHm2 / R_gas_constant * (1 / T2 - 1 / T)))

        init_dH = 60000
        init_KI = 10

        low_bounds        = []
        high_bounds       = []
        initial_estimates = []

        temp1_init = (t1min + t1max) / 2
        temp2_init = (t2min + t2max) / 2

        for index in range(self.fluo.shape[1]):

            p0 = (self.kNs[index], self.bNs[index], self.kUs[index], self.bUs[index],init_KI, init_dH, temp1_init, init_dH, temp2_init)

            low_bound     =  [0.3*x if x>0 else 1.7*x for x in p0[:-5]] 
            low_bound    +=  [0,0,t1min,0,t2min]

            high_bound    = [1.7*x if x>0 else 0.3*x for x in p0[:-5]]  
            high_bound   += [100,3140098,t1max,3140098,t2max] 

            initial_estimates.append(p0)
            low_bounds.append(low_bound)
            high_bounds.append(high_bound)

        self.fit_model_and_fill_params_and_errors(model,initial_estimates,low_bounds,high_bounds,fit_algorithm)

        dHm1_all,      Tm1_all     = [p[5] for p in self.params_all],     [p[6] for p in self.params_all]
        dHms1_sd_all,  Tm1_sd_all  = [p[5] for p in self.errors_abs_all], [p[6] for p in self.errors_abs_all]
        dHm2_all,      Tm2_all     = [p[7] for p in self.params_all],     [p[8] for p in self.params_all]

        self.T_onset      = get_EquilibriumTwoState_model_Tons(dHm1_all,Tm1_all,dHms1_sd_all,Tm1_sd_all)
        self.dG_comb_std  = get_EquilibriumThreeState_model_dG_comb_std(dHm1_all,Tm1_all,dHm2_all,Tm2_all)
       
        return None

    # NOT FINISHED!!!!
    def EquilibriumFourStateDimer(self,t1min,t1max,t2min,t2max,t3min,t3max,fit_algorithm="trf"):

        """

        In this model, the protein is assumed to be in either the native homodimeric state (N2), a non-native dimeric state (I2), 
        a non-native monomeric state (I), or an unfolded monomeric state (U). Reference: https://pubs.acs.org/doi/10.1021/bi0110387
        
        Input

        t1min and t1max are the max and min accepted values for the parameter T1. (N2 ⇆ I2)
        t2min and t2max are the max and min accepted values for the parameter T2. (I2 ⇆ I)
        t3min and t3max are the max and min accepted values for the parameter T3. (2I ⇆ 2U)

        Result - we perform the fitting and assign the values to 

        self.model_name,            self.params_name,               self.fitted_conditions_indexes  
        self.params_all,            self.errors_abs_all,            self.errors_percentage_all      
        self.fluo_predictions_all,  self.std_error_estimate_all,    self.parameters_far_from_bounds 

        """

        params_name = ['kN', 'bN', 'kU', 'bU', 'kI2','kI', 'dHm1', 'T1', 'dHm2', 'T2','dHm3', 'T3']

        self.initialize_model("EquilibriumFourStateDimer",params_name)

        def model(T, kN, bN, kU, bU, kI2,kI, dHm1, T1, dHm2, T2,dHm3, T3):


            dg1 = dHm1*(1/T - 1/T1)
            dg2 = dHm2*(1/T - 1/T2)
            dg3 = dHm3*(1/T - 1/T3)

            K1 = np.exp(-dg1/R_gas_constant*T)
            K2 = np.exp(-dg2/R_gas_constant*T)
            K3 = np.exp(-dg3/R_gas_constant*T)

            K123 = K1*K2*K3

            fraction_u = -K123*(1+K3) + np.sqrt((K123**2)*((1+K3)**2)+8*Pt*(1+K1)*(K123*K3) / 4*Pt*(1+K1))

            fraction_i  = fraction_u           / K3
            fraction_i2 = (fraction_i**2)*Pt*2 / K2
            fraction_n2 = fraction_i2          / K1

            signal_u    = (kU  * T + bU) * fraction_u
            signal_i    = (kI  * T)      * fraction_i
            signal_i2   = (kI2 * T)      * fraction_i2
            signal_n2   = (kN  * T + bN) * fraction_n2

            return signal_u + signal_i + signal_i2 + signal_n2

        init_dH = 60000
        init_KI = 10

        low_bounds        = []
        high_bounds       = []
        initial_estimates = []

        temp1_init = (t1min + t1max) / 2
        temp2_init = (t2min + t2max) / 2
        temp3_init = (t3min + t3max) / 2

        for index in range(self.fluo.shape[1]):

            p0 = (self.kNs[index], self.bNs[index], self.kUs[index], self.bUs[index],init_KI, init_dH, temp1_init, init_dH, temp2_init)

            low_bound     =  [0.3*x if x>0 else 1.7*x for x in p0[:-5]] 
            low_bound    +=  [0,0,t1min,0,t2min]

            high_bound    = [1.7*x if x>0 else 0.3*x for x in p0[:-5]]  
            high_bound   += [100,3140098,t1max,3140098,t2max] 

            initial_estimates.append(p0)
            low_bounds.append(low_bound)
            high_bounds.append(high_bound)

        self.fit_model_and_fill_params_and_errors(model,initial_estimates,low_bounds,high_bounds,fit_algorithm)

        dHm1_all,      Tm1_all     = [p[5] for p in self.params_all],     [p[6] for p in self.params_all]
        dHms1_sd_all,  Tm1_sd_all  = [p[5] for p in self.errors_abs_all], [p[6] for p in self.errors_abs_all]
        dHm2_all,      Tm2_all     = [p[7] for p in self.params_all],     [p[8] for p in self.params_all]

        self.T_onset      = get_EquilibriumTwoState_model_Tons(dHm1_all,Tm1_all,dHms1_sd_all,Tm1_sd_all)
        self.dG_comb_std  = get_EquilibriumThreeState_model_dG_comb_std(dHm1_all,Tm1_all,dHm2_all,Tm2_all)
       
        return None

    def EmpiricalTwoState(self,fit_algorithm="trf",onset_threshold=0.01):

        """

        This model is similar to the Equilibrium two-state, but instead of enthalpy of unfolding, it uses the descriptive parameter Tonset 
        to describe the steepness of the fluorescence curve. 

        Input - float onset_threshold (should be between 0 and 1, i.e, 0.01 means that the fitted T_onset will be
        temperature at which 1 % of the protein is unfolded)

        Result - we perform the fitting and assign the values to 

        self.model_name,            self.params_name,               self.fitted_conditions_indexes  
        self.params_all,            self.errors_abs_all,            self.errors_percentage_all      
        self.fluo_predictions_all,  self.std_error_estimate_all,    self.parameters_far_from_bounds 

        """

        params_name = ['kN', 'bN', 'kU', 'bU', 'T_onset', 'Tm']
        self.initialize_model("EmpiricalTwoState",params_name)

        def model(T, kN, bN, kU, bU, T_onset, Tm):

            return (kN * T+ bN+ (kU * T + bU)* np.exp((T - Tm)*
                np.log(onset_threshold / (1 - onset_threshold)) / (T_onset - Tm))) / (1 + 
                np.exp((T - Tm)* np.log(onset_threshold / (1 - onset_threshold))/ (T_onset - Tm)))

        low_bounds        = []
        high_bounds       = []
        initial_estimates = []

        for index in range(self.fluo.shape[1]):

            tm_init = self.tms_initial[index]

            p0 = (self.kNs[index], self.bNs[index], self.kUs[index], self.bUs[index], tm_init-7,tm_init)

            low_bound_temp  = min(self.temps)+5
            high_bound_temp = max(self.temps)-5

            low_bound     =  [0.3*x if x>0 else 1.7*x for x in p0[:-2]] + [low_bound_temp-5,low_bound_temp]
            high_bound    =  [1.7*x if x>0 else 0.3*x for x in p0[:-2]] + [high_bound_temp-5,high_bound_temp]

            initial_estimates.append(p0)
            low_bounds.append(low_bound)
            high_bounds.append(high_bound)

        self.fit_model_and_fill_params_and_errors(model,initial_estimates,low_bounds,high_bounds,fit_algorithm)

        T_onset_all, Tm_all = [p[4] for p in self.params_all], [p[5] for p in self.params_all]

        self.score = get_EmpiricalTwoState_model_ranking(Tm_all,T_onset_all)

        
        return None

    def EmpiricalThreeState(self,t1min,t1max,t2min,t2max,fit_algorithm="trf",onset_threshold=0.01):

        """

        This model adds the presence of one short-lived protein state to the
        Empirical Two State: native (N), intermediate (I) and unfolded (U). 

        Input

        t1min and t1max are the max and min accepted values for the parameter T1. (N ⇆ I)
        t2min and t2max are the max and min accepted values for the parameter T2. (I ⇆ U)

        Result - we perform the fitting and assign the values to 

        self.model_name,            self.params_name,               self.fitted_conditions_indexes  
        self.params_all,            self.errors_abs_all,            self.errors_percentage_all      
        self.fluo_predictions_all,  self.std_error_estimate_all,    self.parameters_far_from_bounds 

        """

        params_name = ['kN', 'bN', 'kU', 'bU', 'kI', 'T_onset1', 'T1', 'T_onset2', 'T2']
        self.initialize_model("EmpiricalThreeState",params_name)

        def model(T, kN, bN, kU, bU, kI, T_onset1, T1, T_onset2, T2):

            return (kN * T+ bN+ kI* np.exp((T - T1)*
                np.log(onset_threshold / (1 - onset_threshold))/ (T_onset1 - T1))+ 
            (kU * T + bU)*np.exp((T - T2)* np.log(onset_threshold / (1 - onset_threshold))/ (T_onset2 - T2))* 
            np.exp((T - T1)* np.log(onset_threshold / (1 - onset_threshold))/ (T_onset1 - T1))) / (1+ 
            np.exp((T - T1)* np.log(onset_threshold / (1 - onset_threshold))/ (T_onset1 - T1))+ 
            np.exp((T - T2)* np.log(onset_threshold / (1 - onset_threshold))/ (T_onset2 - T2))* 
            np.exp((T - T1)* np.log(onset_threshold / (1 - onset_threshold))/ (T_onset1 - T1)))

        low_bounds        = []
        high_bounds       = []
        initial_estimates = []
        init_KI = 10

        temp1_init = (t1min + t1max) / 2
        temp2_init = (t2min + t2max) / 2

        for index in range(self.fluo.shape[1]):

            p0 = (self.kNs[index], self.bNs[index], self.kUs[index], self.bUs[index], 
                init_KI,temp1_init-8,temp1_init,temp2_init-8,temp2_init)

            low_bound     =  [0.3*x if x>0 else 1.7*x for x in p0[:-5]] + [0]       + [t1min-5,t1min,t2min-5,t2min]
            high_bound    =  [1.7*x if x>0 else 0.3*x for x in p0[:-5]] + [1000]    + [t1max-5,t1max,t2max-5,t2max]

            initial_estimates.append(p0)
            low_bounds.append(low_bound)
            high_bounds.append(high_bound)

        self.fit_model_and_fill_params_and_errors(model,initial_estimates,low_bounds,high_bounds,fit_algorithm)

        T_onset1_all,      T1_all     = [p[5] for p in self.params_all],     [p[6] for p in self.params_all]
        T_onset2_all,      T2_all     = [p[7] for p in self.params_all],     [p[8] for p in self.params_all]

        self.T_eucl_comb = get_EmpiricalThreeState_model_T_eucl_comb(T_onset1_all,T1_all,T_onset2_all,T2_all)

        return None

    def IrreversibleTwoState(self,fit_algorithm="trf"):

        """
        This model assumes that the protein only exists in the native (N) and unfolded (U) state and that the unfolding reaction is irreversible.
        """

        params_name = ['kN', 'bN', 'kU', 'bU', 'Tf', 'Ea']
        self.initialize_model("IrreversibleTwoState",params_name)
       
        def model(T, kN, bN, kU, bU, Tf, Ea):

            xn = 1  # y0 (starting condition) for differential equation

            def ode(T, xn, Tf, Ea):
                """
                ordinary differential equation for fraction native versus temperature
                dxn/dT = -1/v*k(T)*xn

                start_value xn - should be always 1 because at the start of assay we assume everything is folded
                xn - fraction native (xn + xagg = 1)
                k(T) - temperature-dependent rate constant of aggregation
                """
                return -1 / self.scan_rate * arrhenius(T, Tf, Ea) * xn

            """
            Returns aggregation signal at given temperature
            k, b - baseline parameters (N or U state)
            xn, xu - fraciton native/unfolded, xn + xu = 1

            Signal(T) = kU*T + bU + (kN*T + bN - kU*T - bU) * xn
            """
            # step 1: numerically integrate agg_ode for given parameters - gives xn(T)
            ivp_result = solve_ivp(ode,t_span=[min(T), max(T)],t_eval=T,y0=[1],args=(Tf, Ea),method="BDF")

            # step 2: Return the result of the signal
            # return kU*t + bU + (kN*t + bN - kU*t - bU)*ivp_result.sol(t)[0]
            return kU * T + bU + (kN * T + bN - kU * T - bU) * ivp_result.y[0, :]

        low_bounds        = []
        high_bounds       = []
        initial_estimates = []
        init_Tf = min(self.temps) + (max(self.temps) - min(self.temps)) / 2
        init_Ea = 50000

        for index in range(self.fluo.shape[1]):

            p0 = (self.kNs[index], self.bNs[index], self.kUs[index], self.bUs[index], init_Tf,init_Ea)

            low_bound     =  [0.6*x if x>0 else 1.4*x for x in p0[:-2]] + [min(self.temps)-100,0]
            high_bound    =  [1.4*x if x>0 else 0.6*x for x in p0[:-2]] + [max(self.temps)+100,init_Ea*1E4]

            initial_estimates.append(p0)
            low_bounds.append(low_bound)
            high_bounds.append(high_bound)

        self.fit_model_and_fill_params_and_errors(model,initial_estimates,low_bounds,high_bounds,fit_algorithm)

        Tf_all, Ea_all = [p[4] for p in self.params_all], [p[5] for p in self.params_all]

        self.pkd = get_IrrevTwoState_pkd(Tf_all,Ea_all)

        return None

if False:

    t = DSF_molten_prot_fit()
    t.load_nanoDSF_xlsx('/home/osvaldo/spc_shiny_servers/foldA_moltenP_apps/moltenprot/www/demo.xlsx')
    
